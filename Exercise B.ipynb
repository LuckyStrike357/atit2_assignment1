{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B KNN MNIST\n",
    "\n",
    "- What is the error rate of KNN on the test set?\n",
    "- What is the error rate for each label (number)?\n",
    "\n",
    "Do for k = 2, 4, 8\n",
    "- How does the choice of k influence the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.spatial.distance\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "plt.set_cmap('gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.keras.datasets.mnist.load_data()[0]\n",
    "X_train, Y_train = train[0], train[1]\n",
    "\n",
    "test = tf.keras.datasets.mnist.load_data()[1]\n",
    "X_test, Y_test = test[0], test[1]\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "m = X_train.shape[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([n_train, m])\n",
    "X_test = X_test.reshape([n_test, m])\n",
    "\n",
    "idx = np.random.randint(n_train, size=1000)\n",
    "x_train_sample = X_train[idx]\n",
    "y_train_sample = Y_train[idx]\n",
    "\n",
    "idx = np.random.randint(n_test, size=100)\n",
    "x_test_sample = X_test[idx]\n",
    "y_test_sample = Y_test[idx]\n",
    "#print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "dists = scipy.spatial.distance.cdist(x_train_sample, x_test_sample, metric='euclid')\n",
    "idx_nearest = np.argpartition(dists, k, axis = 0)[:k]\n",
    "#nearest_dists = np.take(x_train_sample, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_train_sample[idx_nearest]\n",
    "pred = np.ndarray.transpose(pred)\n",
    "actuals = y_test_sample\n",
    "prediction = np.array([])\n",
    "\n",
    "for row in pred:\n",
    "    count = np.bincount(row)\n",
    "    prediction = np.append(prediction, int(np.argmax(count)))\n",
    "\n",
    "prediction = prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 8 8 0 5 1 7 1 0 3 3 6 5 3 2 3 6 7 3 4 9 6 2 5 2 5 3 1 6 1 8 6 1 4 1 9 8\n",
      " 3 0 8 1 4 4 5 8 8 6 2 4 3 2 9 4 6 1 4 8 7 1 0 1 7 7 2 7 5 8 8 6 0 3 3 5 0\n",
      " 6 1 4 0 3 7 8 1 2 4 4 7 8 4 9 7 2 6 3 8 3 8 2 6 2 2]\n",
      "[4 8 8 0 5 1 7 1 0 3 3 6 5 3 7 3 6 7 3 4 9 6 2 5 2 5 3 1 6 1 8 6 1 9 1 9 1\n",
      " 3 0 8 1 4 4 5 8 5 6 2 4 3 2 9 4 6 1 9 8 7 1 0 1 7 7 2 7 5 8 8 6 0 3 3 3 0\n",
      " 6 1 4 0 3 7 8 1 2 4 4 7 8 4 9 7 2 6 3 8 3 8 1 6 2 2]\n"
     ]
    }
   ],
   "source": [
    "print (actuals)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We use 1-f1_score since it is an better indicator of quality than the error rate.'''\n",
    "f1scorek3 = f1_score(actuals, prediction, average=\"micro\")\n",
    "#y_true = [0, 1, 2, 0, 1, 2]\n",
    "#y_pred = [0, 2, 1, 0, 0, 1]\n",
    "#f1scorek3 = f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for KNN with k = 3 on this Dataset is 0.06999999999999995\n"
     ]
    }
   ],
   "source": [
    "print (\"The error rate for KNN with k = 3 on this Dataset is {}\".format((1 - f1scorek3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(k):\n",
    "    dists = scipy.spatial.distance.cdist(x_train_sample, x_test_sample, metric='euclid')\n",
    "    idx_nearest = np.argpartition(dists, k, axis = 0)[:k]\n",
    "    nearest_dists = np.take(x_train_sample, idx)\n",
    "    \n",
    "    pred = y_train_sample[idx_nearest]\n",
    "    pred = np.ndarray.transpose(pred)\n",
    "    actuals = y_test_sample\n",
    "    prediction = np.array([])\n",
    "\n",
    "    for row in pred:\n",
    "        count = np.bincount(row)\n",
    "        prediction = np.append(prediction, int(np.argmax(count)))\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    '''We use 1-f1_score since it is an better indicator of quality than the error rate.'''\n",
    "    calcf1score = f1_score(actuals, prediction, average = 'micro')\n",
    "    print (\"The error rate for KNN with k = {} on this Dataset is {}\".format(k, (1 - calcf1score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for KNN with k = 2 on this Dataset is 0.10999999999999999\n",
      "The error rate for KNN with k = 4 on this Dataset is 0.06999999999999995\n",
      "The error rate for KNN with k = 8 on this Dataset is 0.06999999999999995\n"
     ]
    }
   ],
   "source": [
    "f1score(2)\n",
    "f1score(4)\n",
    "f1score(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
